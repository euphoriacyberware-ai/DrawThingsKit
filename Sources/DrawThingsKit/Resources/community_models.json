{
  "checkpoints": [
    {
      "name": "3D Model (Redshift v1)",
      "file": "redshift_v1_f16.ckpt",
      "version": "v1",
      "prefix": "redshift style ",
      "default_scale": 8,
      "text_encoder": "redshift_v1_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "3D Model 768 (Redshift 768)",
      "file": "redshift_768_v_f16.ckpt",
      "version": "v2",
      "prefix": "redshift style ",
      "default_scale": 12,
      "text_encoder": "redshift_768_v_open_clip_vit_h14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "AloeVera's SimpMaker 3K1",
      "file": "aloeveras_simpmaker_3k1_f16.ckpt",
      "version": "v1",
      "default_scale": 8,
      "upcast_attention": false
    },
    {
      "name": "Analog (v1)",
      "file": "analog_v1_f16.ckpt",
      "version": "v1",
      "prefix": "analog style ",
      "default_scale": 8,
      "text_encoder": "analog_v1_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Animagine XL v3.1",
      "file": "animagine_xl_v3.1_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "animagine_xl_v3.1_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "animagine_xl_v3.1_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Animagine XL v3.1 (8-bit)",
      "file": "animagine_xl_v3.1_q6p_q8p.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "animagine_xl_v3.1_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "animagine_xl_v3.1_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "AnimateLCM SVD XT v1.1",
      "file": "animatelcm_svd_xt_v1.1_f16.ckpt",
      "version": "svd_i2v",
      "modifier": "none",
      "default_scale": 8,
      "text_encoder": "open_clip_vit_h14_vision_model_f16.ckpt",
      "clip_encoder": "open_clip_vit_h14_visual_proj_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "AnimateLCM SVD XT v1.1 (8-bit)",
      "file": "animatelcm_svd_xt_v1.1_q6p_q8p.ckpt",
      "version": "svd_i2v",
      "modifier": "none",
      "default_scale": 8,
      "text_encoder": "open_clip_vit_h14_vision_model_f16.ckpt",
      "clip_encoder": "open_clip_vit_h14_visual_proj_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Anime (Anything v3)",
      "file": "anything_v3_f16.ckpt",
      "version": "v1",
      "default_scale": 8,
      "autoencoder": "anything_v3_vae_f16.ckpt",
      "text_encoder": "anything_v3_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Anime (Waifu Diffusion v1.3)",
      "file": "wd_v1.3_f16.ckpt",
      "version": "v1",
      "default_scale": 8,
      "upcast_attention": false
    },
    {
      "name": "AniSora v3.2 I2V Wan 2.2 A14B High Noise Expert",
      "file": "anisora_v3.2_i2v_wan_2.2_a14b_hne_q8p.ckpt",
      "version": "wan_v2.1_14b",
      "modifier": "inpainting",
      "note": "[AniSora v3.2](https://huggingface.co/IndexTeam/Index-anisora) is a state-of-the-art image-to-video model fine-tuned by Bilibili for anime generation.",
      "default_scale": 12,
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "upcast_attention": false
    },
    {
      "name": "AniSora v3.2 I2V Wan 2.2 A14B High Noise Expert (6-bit, SVDQuant)",
      "file": "anisora_v3.2_i2v_wan_2.2_a14b_hne_q6p_svd.ckpt",
      "version": "wan_v2.1_14b",
      "modifier": "inpainting",
      "note": "[AniSora v3.2](https://huggingface.co/IndexTeam/Index-anisora) is a state-of-the-art image-to-video model fine-tuned by Bilibili for anime generation.",
      "default_scale": 12,
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "upcast_attention": false
    },
    {
      "name": "AniSora v3.2 I2V Wan 2.2 A14B Low Noise Expert",
      "file": "anisora_v3.2_i2v_wan_2.2_a14b_lne_q8p.ckpt",
      "version": "wan_v2.1_14b",
      "modifier": "inpainting",
      "note": "[AniSora v3.2](https://huggingface.co/IndexTeam/Index-anisora) is a state-of-the-art image-to-video model fine-tuned by Bilibili for anime generation.",
      "default_scale": 12,
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "upcast_attention": false
    },
    {
      "name": "AniSora v3.2 I2V Wan 2.2 A14B Low Noise Expert (6-bit, SVDQuant)",
      "file": "anisora_v3.2_i2v_wan_2.2_a14b_lne_q6p_svd.ckpt",
      "version": "wan_v2.1_14b",
      "modifier": "inpainting",
      "note": "[AniSora v3.2](https://huggingface.co/IndexTeam/Index-anisora) is a state-of-the-art image-to-video model fine-tuned by Bilibili for anime generation.",
      "default_scale": 12,
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Arcane (v3)",
      "file": "arcane_v3_f16.ckpt",
      "version": "v1",
      "prefix": "arcane style ",
      "default_scale": 8,
      "text_encoder": "arcane_v3_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Artsy Vibe v1",
      "file": "artsy_vibe_v1_q8p.ckpt",
      "version": "flux1",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Artsy Vibe v1 (5-bit, SVDQuant)",
      "file": "artsy_vibe_v1_q5p_svd.ckpt",
      "version": "flux1",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Balloon Art (v1)",
      "file": "balloonart_v1_f16.ckpt",
      "version": "v1",
      "prefix": "balloonart ",
      "default_scale": 8,
      "text_encoder": "balloonart_v1_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Chroma v47 Detail Calibrated",
      "file": "chroma_v47_detail_calibrated_q8p.ckpt",
      "version": "flux1",
      "note": "See more about [Chroma](https://huggingface.co/lodestones/Chroma).",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Chroma v47 Detail Calibrated (5-bit)",
      "file": "chroma_v47_detail_calibrated_q5p.ckpt",
      "version": "flux1",
      "note": "See more about [Chroma](https://huggingface.co/lodestones/Chroma).",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Chroma v48 Detail Calibrated",
      "file": "chroma_v48_detail_calibrated_q8p.ckpt",
      "version": "flux1",
      "note": "See more about [Chroma](https://huggingface.co/lodestones/Chroma).",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Chroma v48 Detail Calibrated (5-bit)",
      "file": "chroma_v48_detail_calibrated_q5p.ckpt",
      "version": "flux1",
      "note": "See more about [Chroma](https://huggingface.co/lodestones/Chroma).",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Chroma1 HD",
      "file": "chroma_1_hd_r0.1_q8p.ckpt",
      "version": "flux1",
      "note": "See more about [Chroma1 HD](https://huggingface.co/lodestones/Chroma1-HD).",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Chroma1 HD (5-bit)",
      "file": "chroma_1_hd_r0.1_q5p.ckpt",
      "version": "flux1",
      "note": "See more about [Chroma1 HD](https://huggingface.co/lodestones/Chroma1-HD).",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "ChronoEdit 14B",
      "file": "chronoedit_14b_q8p.ckpt",
      "version": "wan_v2.1_14b",
      "modifier": "inpainting",
      "note": "[ChronoEdit 14B](https://research.nvidia.com/labs/toronto-ai/chronoedit/) is a image edit model fine-tuned from Wan 2.1 14B video model, that prefers 29-frame or 5-frame generation.",
      "default_scale": 15,
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "ChronoEdit 14B (6-bit, SVDQuant)",
      "file": "chronoedit_14b_q6p_svd.ckpt",
      "version": "wan_v2.1_14b",
      "modifier": "inpainting",
      "note": "[ChronoEdit 14B](https://research.nvidia.com/labs/toronto-ai/chronoedit/) is a image edit model fine-tuned from Wan 2.1 14B video model, that prefers 29-frame or 5-frame generation.",
      "default_scale": 15,
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Classic Animation (v1)",
      "file": "classicanim_v1_f16.ckpt",
      "version": "v1",
      "prefix": "classic disney style ",
      "default_scale": 8,
      "text_encoder": "classicanim_v1_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "ColorfulXL v6.0",
      "file": "colorfulxl_v6.0_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "colorfulxl_v6.0_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "colorfulxl_v6.0_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "ColorfulXL v6.0 (8-bit)",
      "file": "colorfulxl_v6.0_q6p_q8p.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "colorfulxl_v6.0_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "colorfulxl_v6.0_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Counterfeit v3.0",
      "file": "counterfeit_v3.0_f16.ckpt",
      "version": "v1",
      "modifier": "none",
      "default_scale": 8,
      "text_encoder": "counterfeit_v3.0_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Counterfeit v3.0 (8-bit)",
      "file": "counterfeit_v3.0_q6p_q8p.ckpt",
      "version": "v1",
      "modifier": "none",
      "default_scale": 8,
      "text_encoder": "counterfeit_v3.0_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Cyberpunk Anime",
      "file": "cyberpunk_anime_f16.ckpt",
      "version": "v1",
      "prefix": "dgs illustration style ",
      "default_scale": 8,
      "text_encoder": "cyberpunk_anime_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Deliberate v2.0 (8-bit)",
      "file": "deliberate_v2_q6p_q8p.ckpt",
      "version": "v1",
      "default_scale": 8,
      "text_encoder": "deliberate_v2_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "devMODE v0.3 Turbo",
      "file": "devmode_v0.3_turbo_q8p.ckpt",
      "version": "flux1",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "devMODE v0.3 Turbo (5-bit, SVDQuant)",
      "file": "devmode_v0.3_turbo_q5p_svd.ckpt",
      "version": "flux1",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Disney Pixar Cartoon Type B (8-bit)",
      "file": "disney_pixar_cartoon_type_b_q6p_q8p.ckpt",
      "version": "v1",
      "default_scale": 8,
      "text_encoder": "disney_pixar_cartoon_type_b_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "DnD Classes and Species",
      "file": "dnd_classes_and_species_f16.ckpt",
      "version": "v1",
      "default_scale": 8,
      "text_encoder": "dnd_classes_and_species_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "DreamShaper v8",
      "file": "dreamshaper_v8_f16.ckpt",
      "version": "v1",
      "modifier": "none",
      "default_scale": 12,
      "text_encoder": "dreamshaper_v8_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "DreamShaper v8 (8-bit)",
      "file": "dreamshaper_v8_q6p_q8p.ckpt",
      "version": "v1",
      "modifier": "none",
      "default_scale": 12,
      "text_encoder": "dreamshaper_v8_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "DreamShaper XL v2.1 Turbo",
      "file": "dreamshaper_xl_v2.1_turbo_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "dreamshaper_xl_v2.1_turbo_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "dreamshaper_xl_v2.1_turbo_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "DreamShaper XL v2.1 Turbo (8-bit)",
      "file": "dreamshaper_xl_v2.1_turbo_q6p_q8p.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "dreamshaper_xl_v2.1_turbo_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "dreamshaper_xl_v2.1_turbo_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Dungeons and Diffusion (30000)",
      "file": "dnd_30000_f16.ckpt",
      "version": "v1",
      "default_scale": 8,
      "text_encoder": "dnd_30000_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Elden Ring (v3)",
      "file": "eldenring_v3_f16.ckpt",
      "version": "v1",
      "prefix": "elden ring style ",
      "default_scale": 8,
      "text_encoder": "eldenring_v3_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "F222",
      "file": "f222_f16.ckpt",
      "version": "v1",
      "default_scale": 8,
      "upcast_attention": false
    },
    {
      "name": "FLUX.1 [dev]",
      "file": "flux_1_dev_q8p.ckpt",
      "version": "flux1",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "FLUX.1 [dev] (5-bit)",
      "file": "flux_1_dev_q5p.ckpt",
      "version": "flux1",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "FLUX.1 [dev] (Exact)",
      "file": "flux_1_dev_f16.ckpt",
      "version": "flux1",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "t5_xxl_encoder_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "FLUX.1 [dev] De-distill",
      "file": "flux_1_dev_de_distill_q8p.ckpt",
      "version": "flux1",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "FLUX.1 [dev] De-distill (5-bit)",
      "file": "flux_1_dev_de_distill_q5p.ckpt",
      "version": "flux1",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "FLUX.1 Canny [dev]",
      "file": "flux_1_canny_dev_q8p.ckpt",
      "version": "flux1",
      "modifier": "canny",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "FLUX.1 Canny [dev] (5-bit)",
      "file": "flux_1_canny_dev_q5p.ckpt",
      "version": "flux1",
      "modifier": "canny",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "FLUX.1 Depth [dev]",
      "file": "flux_1_depth_dev_q8p.ckpt",
      "version": "flux1",
      "modifier": "depth",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "FLUX.1 Depth [dev] (5-bit)",
      "file": "flux_1_depth_dev_q5p.ckpt",
      "version": "flux1",
      "modifier": "depth",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "FLUX.1 Fill [dev]",
      "file": "flux_1_fill_dev_q8p.ckpt",
      "version": "flux1",
      "modifier": "inpainting",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "FLUX.1 Fill [dev] (5-bit)",
      "file": "flux_1_fill_dev_q5p.ckpt",
      "version": "flux1",
      "modifier": "inpainting",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "FLUX.1 Kontext [dev]",
      "file": "flux_1_kontext_dev_q8p.ckpt",
      "version": "flux1",
      "modifier": "kontext",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "FLUX.1 Kontext [dev] (5-bit)",
      "file": "flux_1_kontext_dev_q5p.ckpt",
      "version": "flux1",
      "modifier": "kontext",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "FLUX.1 Kontext [dev] (Exact)",
      "file": "flux_1_kontext_dev_f16.ckpt",
      "version": "flux1",
      "modifier": "kontext",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "t5_xxl_encoder_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "FLUX.1 Krea [dev]",
      "file": "flux_1_krea_dev_q8p.ckpt",
      "version": "flux1",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "FLUX.1 Krea [dev] (5-bit)",
      "file": "flux_1_krea_dev_q5p.ckpt",
      "version": "flux1",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Ghibli (v1)",
      "file": "ghibli_v1_f16.ckpt",
      "version": "v1",
      "prefix": "ghibli style ",
      "default_scale": 8,
      "text_encoder": "ghibli_v1_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "H&A's 3DKX 1.1",
      "file": "hna_3dkx_1.1_f16.ckpt",
      "version": "v1",
      "prefix": "a 3d render / cartoon of ",
      "default_scale": 8,
      "text_encoder": "hna_3dkx_1.1_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Hassanblend (v1.5.1.2)",
      "file": "hassanblend_v1.5.1.2_f16.ckpt",
      "version": "v1",
      "default_scale": 8,
      "text_encoder": "hassanblend_v1.5.1.2_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "HiDream E1-1 (Exact)",
      "file": "hidream_e1_1_f16.ckpt",
      "version": "hidream_i1",
      "modifier": "editing",
      "note": "[HiDream-E1-1](https://huggingface.co/HiDream-ai/HiDream-E1-1) is an image editing model built on HiDream-I1. It is MIT-licensed and commercially friendly. Trained at dynamic resolutions (around 1MP) using a Flow Matching objective, the model performs best with trailing samplers and 30\u201350 sampling steps.",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "llama_3.1_8b_instruct_f16.ckpt",
      "clip_encoder": "long_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "HiDream I1 [dev] (Exact)",
      "file": "hidream_i1_dev_f16.ckpt",
      "version": "hidream_i1",
      "note": "[HiDream-I1 [dev]](https://huggingface.co/HiDream-ai/HiDream-I1-Dev) is a state-of-the-art open-source image generation model known for its strong prompt adherence across diverse styles, including photorealistic, cartoon, and artistic. It is MIT-licensed and commercially friendly. The model is trained at multiple resolutions using a Flow Matching objective; trailing samplers yield the best results, with 20\u201330 sampling steps recommended. Text guidance is not effective for this model.",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "llama_3.1_8b_instruct_f16.ckpt",
      "clip_encoder": "long_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "HiDream I1 [fast] (Exact)",
      "file": "hidream_i1_fast_f16.ckpt",
      "version": "hidream_i1",
      "note": "[HiDream-I1 [fast]](https://huggingface.co/HiDream-ai/HiDream-I1-Fast) is a state-of-the-art open-source image generation model known for its strong prompt adherence across diverse styles, including photorealistic, cartoon, and artistic. It is MIT-licensed and commercially friendly. The model is trained at multiple resolutions using a Flow Matching objective; trailing samplers yield the best results, with 10\u201320 sampling steps recommended. Text guidance is not effective for this model.",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "llama_3.1_8b_instruct_f16.ckpt",
      "clip_encoder": "long_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "HiDream I1 [full] (Exact)",
      "file": "hidream_i1_full_f16.ckpt",
      "version": "hidream_i1",
      "note": "[HiDream-I1 [full]](https://huggingface.co/HiDream-ai/HiDream-I1-Full) is a state-of-the-art open-source image generation model known for its exceptional prompt adherence across a wide range of styles, including photorealistic, cartoon, and artistic. It is MIT-licensed and commercially friendly. The model is trained at multiple resolutions using a Flow Matching objective; trailing samplers yield the best results, with 30\u201350 sampling steps recommended.",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "llama_3.1_8b_instruct_f16.ckpt",
      "clip_encoder": "long_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Hunyuan Video T2V 720p",
      "file": "hunyuan_video_t2v_720p_q8p.ckpt",
      "version": "hunyuan_video",
      "note": "[Hunyuan Video](https://huggingface.co/tencent/HunyuanVideo) is a state-of-the-art text-to-video model developed by Tencent. It can generate video clips of up to 5 seconds in length. The recommended resolutions are 960\u00d7544 or 1280\u00d7720. The model supports up to 129 frames, with a recommended shift value of 7.0.",
      "default_scale": 12,
      "autoencoder": "hunyuan_video_vae_f16.ckpt",
      "text_encoder": "llava_llama_3_8b_v1.1_q8p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Hunyuan Video T2V 720p (5-bit, SVDQuant)",
      "file": "hunyuan_video_t2v_720p_q5p_svd.ckpt",
      "version": "hunyuan_video",
      "note": "[Hunyuan Video](https://huggingface.co/tencent/HunyuanVideo) is a state-of-the-art text-to-video model developed by Tencent. It can generate video clips of up to 5 seconds in length. The recommended resolutions are 960\u00d7544 or 1280\u00d7720. The model supports up to 129 frames, with a recommended shift value of 7.0.",
      "default_scale": 12,
      "autoencoder": "hunyuan_video_vae_f16.ckpt",
      "text_encoder": "llava_llama_3_8b_v1.1_q8p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "iCatcher Cartoon",
      "file": "icatcher_cartoon_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "icatcher_cartoon_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "icatcher_cartoon_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "iCatcher Cartoon (8-bit)",
      "file": "icatcher_cartoon_q6p_q8p.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "icatcher_cartoon_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "icatcher_cartoon_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "iCatcher Realistic",
      "file": "icatcher_realistic_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "icatcher_realistic_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "icatcher_realistic_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "iCatcher Realistic (8-bit)",
      "file": "icatcher_realistic_q6p_q8p.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "icatcher_realistic_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "icatcher_realistic_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Inkpunk (v2)",
      "file": "inkpunk_v2_f16.ckpt",
      "version": "v1",
      "prefix": "nvinkpunk ",
      "default_scale": 8,
      "text_encoder": "inkpunk_v2_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Juggernaut Reborn",
      "file": "juggernaut_reborn_f16.ckpt",
      "version": "v1",
      "modifier": "none",
      "default_scale": 12,
      "text_encoder": "juggernaut_reborn_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Juggernaut Reborn (8-bit)",
      "file": "juggernaut_reborn_q6p_q8p.ckpt",
      "version": "v1",
      "modifier": "none",
      "default_scale": 12,
      "text_encoder": "juggernaut_reborn_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Juggernaut XL Ragnarok",
      "file": "juggernaut_xl_ragnarok_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "juggernaut_xl_ragnarok_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "juggernaut_xl_ragnarok_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Juggernaut XL Ragnarok (8-bit)",
      "file": "juggernaut_xl_ragnarok_q6p_q8p.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "juggernaut_xl_ragnarok_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "juggernaut_xl_ragnarok_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Juggernaut XL v9",
      "file": "juggernaut_xl_v9_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "juggernaut_xl_v9_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "juggernaut_xl_v9_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Juggernaut XL v9 (8-bit)",
      "file": "juggernaut_xl_v9_q6p_q8p.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "juggernaut_xl_v9_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "juggernaut_xl_v9_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Juggernaut XL v9 Lightning",
      "file": "juggernaut_xl_v9_lightning_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "juggernaut_xl_v9_lightning_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "juggernaut_xl_v9_lightning_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Juggernaut XL v9 Lightning (8-bit)",
      "file": "juggernaut_xl_v9_lightning_q6p_q8p.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "juggernaut_xl_v9_lightning_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "juggernaut_xl_v9_lightning_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Juggernaut XL X",
      "file": "juggernaut_xl_x_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "juggernaut_xl_x_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "juggernaut_xl_x_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Juggernaut XL X (8-bit)",
      "file": "juggernaut_xl_x_q6p_q8p.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "juggernaut_xl_x_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "juggernaut_xl_x_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Kwai Kolors 1.0",
      "file": "kwai_kolors_1.0_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "chatglm3_6b_q6p_q8p.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Kwai Kolors 1.0 (8-bit)",
      "file": "kwai_kolors_1.0_q6p_q8p.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "chatglm3_6b_q6p_q8p.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Kwai Kolors Inpainting 1.0",
      "file": "kwai_kolors_inpainting_1.0_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "inpainting",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "chatglm3_6b_q6p_q8p.ckpt",
      "upcast_attention": true
    },
    {
      "name": "Kwai Kolors Inpainting 1.0 (8-bit)",
      "file": "kwai_kolors_inpainting_1.0_q6p_q8p.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "inpainting",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "chatglm3_6b_q6p_q8p.ckpt",
      "upcast_attention": true
    },
    {
      "name": "MajicMIX Realistic v7",
      "file": "majicmix_realistic_v7_f16.ckpt",
      "version": "v1",
      "modifier": "none",
      "default_scale": 8,
      "text_encoder": "majicmix_realistic_v7_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "MajicMIX Realistic v7 (8-bit)",
      "file": "majicmix_realistic_v7_q6p_q8p.ckpt",
      "version": "v1",
      "modifier": "none",
      "default_scale": 8,
      "text_encoder": "majicmix_realistic_v7_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Modern Disney (v1)",
      "file": "modi_v1_f16.ckpt",
      "version": "v1",
      "prefix": "modern disney style ",
      "default_scale": 8,
      "text_encoder": "modi_v1_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Multi-Style (Nitro Diffusion v1)",
      "file": "nitro_v1_f16.ckpt",
      "version": "v1",
      "default_scale": 8,
      "text_encoder": "nitro_v1_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Openjourney",
      "file": "mdjrny_v4_f16.ckpt",
      "version": "v1",
      "prefix": "mdjrny-v4 style ",
      "default_scale": 8,
      "text_encoder": "mdjrny_v4_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Outfitting Fusion Virtual Try-on (Full-Body)",
      "file": "ootd_vton_full_body_1.0_f16.ckpt",
      "version": "v1",
      "modifier": "double",
      "default_scale": 16,
      "autoencoder": "vae_ft_mse_840000_f16.ckpt",
      "text_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Outfitting Fusion Virtual Try-on (Upper-Body)",
      "file": "ootd_vton_upper_body_1.0_f16.ckpt",
      "version": "v1",
      "modifier": "double",
      "default_scale": 16,
      "autoencoder": "vae_ft_mse_840000_f16.ckpt",
      "text_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Paper Cut (v1)",
      "file": "papercut_v1_f16.ckpt",
      "version": "v1",
      "prefix": "papercut ",
      "default_scale": 8,
      "text_encoder": "papercut_v1_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "PixelWave 10",
      "file": "pixelwave_10_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "pixelwave_10_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "pixelwave_10_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "PixelWave 10 (8-bit)",
      "file": "pixelwave_10_q6p_q8p.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "pixelwave_10_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "pixelwave_10_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "PixelWave FLUX.1 Schnell 04",
      "file": "pixelwave_flux_1_schnell_04_q8p.ckpt",
      "version": "flux1",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "PixelWave FLUX.1 Schnell 04 (5-bit, SVDQuant)",
      "file": "pixelwave_flux_1_schnell_04_q5p_svd.ckpt",
      "version": "flux1",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "PixelWave v9",
      "file": "pixelwave_v9_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "pixelwave_v9_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "pixelwave_v9_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "PixelWave v9 (8-bit)",
      "file": "pixelwave_v9_q6p_q8p.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "pixelwave_v9_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "pixelwave_v9_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Playground v2",
      "file": "playground_v2_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Playground v2 (8-bit)",
      "file": "playground_v2_q6p_q8p.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Playground v2.5",
      "file": "playground_v2.5_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Playground v2.5 (8-bit)",
      "file": "playground_v2.5_q6p_q8p.ckpt",
      "version": "sdxl_base_v0.9",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Proteus v0.3",
      "file": "proteus_v0.3_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "proteus_v0.3_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "proteus_v0.3_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Proteus v0.3 (8-bit)",
      "file": "proteus_v0.3_q6p_q8p.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "proteus_v0.3_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "proteus_v0.3_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Qwen Image 1.0 (BF16, Exact)",
      "file": "qwen_image_1.0_bf16.ckpt",
      "version": "qwen_image",
      "note": "[Qwen Image](https://huggingface.co/Qwen/Qwen-Image) is a state-of-the-art open-source image generation model known for its exceptional text layout and prompt adherence across a wide range of styles, including photorealistic, cartoon, and artistic. It is Apache 2.0-licensed and commercially friendly. The model is trained at multiple resolutions using a Flow Matching objective; trailing samplers yield the best results, with 30\u201350 sampling steps recommended. The BF16 version is only compatible with macOS 15, iOS 18 and above.",
      "default_scale": 16,
      "autoencoder": "qwen_image_vae_f16.ckpt",
      "text_encoder": "qwen_2.5_vl_7b_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Qwen Image 1.0 (Exact)",
      "file": "qwen_image_1.0_f16.ckpt",
      "version": "qwen_image",
      "note": "[Qwen Image](https://huggingface.co/Qwen/Qwen-Image) is a state-of-the-art open-source image generation model known for its exceptional text layout and prompt adherence across a wide range of styles, including photorealistic, cartoon, and artistic. It is Apache 2.0-licensed and commercially friendly. The model is trained at multiple resolutions using a Flow Matching objective; trailing samplers yield the best results, with 30\u201350 sampling steps recommended.",
      "default_scale": 16,
      "autoencoder": "qwen_image_vae_f16.ckpt",
      "text_encoder": "qwen_2.5_vl_7b_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Qwen Image Edit 2509 (BF16, Exact)",
      "file": "qwen_image_edit_2509_bf16.ckpt",
      "version": "qwen_image",
      "modifier": "qwenimage_edit_plus",
      "note": "[Qwen Image Edit 2509](https://huggingface.co/Qwen/Qwen-Image-2509) is a state-of-the-art open-source image edit model excels at image edit tasks such as background alternation, style transfer, object removal etc. It is Apache 2.0-licensed and commercially friendly. The model is trained at multiple resolutions using a Flow Matching objective; trailing samplers yield the best results, with 30\u201350 sampling steps recommended. This is an update in Sep, 2025. The BF16 version is only compatible with macOS 15, iOS 18 and above.",
      "default_scale": 16,
      "autoencoder": "qwen_image_vae_f16.ckpt",
      "text_encoder": "qwen_2.5_vl_7b_f16.ckpt",
      "clip_encoder": "qwen_2.5_vl_7b_vit_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Qwen Image Edit 2509 (Exact)",
      "file": "qwen_image_edit_2509_f16.ckpt",
      "version": "qwen_image",
      "modifier": "qwenimage_edit_plus",
      "note": "[Qwen Image Edit 2509](https://huggingface.co/Qwen/Qwen-Image-2509) is a state-of-the-art open-source image edit model excels at image edit tasks such as background alternation, style transfer, object removal etc. It is Apache 2.0-licensed and commercially friendly. The model is trained at multiple resolutions using a Flow Matching objective; trailing samplers yield the best results, with 30\u201350 sampling steps recommended. This is an update in Sep, 2025.",
      "default_scale": 16,
      "autoencoder": "qwen_image_vae_f16.ckpt",
      "text_encoder": "qwen_2.5_vl_7b_f16.ckpt",
      "clip_encoder": "qwen_2.5_vl_7b_vit_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "RayFLUX v3.0",
      "file": "rayflux_v3.0_aio_q8p.ckpt",
      "version": "flux1",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "RayFLUX v3.0 (5-bit)",
      "file": "rayflux_v3.0_aio_q5p.ckpt",
      "version": "flux1",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Realistic Vision v5.1",
      "file": "realistic_vision_v5.1_f16.ckpt",
      "version": "v1",
      "modifier": "none",
      "default_scale": 12,
      "text_encoder": "realistic_vision_v5.1_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Realistic Vision v5.1 (8-bit)",
      "file": "realistic_vision_v5.1_q6p_q8p.ckpt",
      "version": "v1",
      "modifier": "none",
      "default_scale": 12,
      "text_encoder": "realistic_vision_v5.1_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "RealVisXL v4.0",
      "file": "realvisxl_v4.0_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "realvisxl_v4.0_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "realvisxl_v4.0_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "RealVisXL v4.0 (8-bit)",
      "file": "realvisxl_v4.0_q6p_q8p.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "realvisxl_v4.0_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "realvisxl_v4.0_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Rev Animated v1.22",
      "file": "rev_animated_v1.22_f16.ckpt",
      "version": "v1",
      "modifier": "none",
      "default_scale": 8,
      "text_encoder": "rev_animated_v1.22_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Rev Animated v1.22 (8-bit)",
      "file": "rev_animated_v1.22_q6p_q8p.ckpt",
      "version": "v1",
      "modifier": "none",
      "default_scale": 8,
      "text_encoder": "rev_animated_v1.22_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "SamDoesArt (v3)",
      "file": "samdoesart_v3_f16.ckpt",
      "version": "v1",
      "prefix": "samdoesart ",
      "default_scale": 8,
      "text_encoder": "samdoesart_v3_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "schnellMODE v3.3",
      "file": "schnellmode_v3.3_q8p.ckpt",
      "version": "flux1",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "schnellMODE v3.3 (5-bit, SVDQuant)",
      "file": "schnellmode_v3.3_q5p_svd.ckpt",
      "version": "flux1",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "SD3 Large 3.5",
      "file": "sd3_large_3.5_q8p.ckpt",
      "version": "sd3_large",
      "default_scale": 16,
      "autoencoder": "sd3_vae_f16.ckpt",
      "text_encoder": "open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "SD3 Large 3.5 (6-bit)",
      "file": "sd3_large_3.5_q6p.ckpt",
      "version": "sd3_large",
      "default_scale": 16,
      "autoencoder": "sd3_vae_f16.ckpt",
      "text_encoder": "open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "SD3 Large 3.5 (Exact)",
      "file": "sd3_large_3.5_f16.ckpt",
      "version": "sd3_large",
      "default_scale": 16,
      "autoencoder": "sd3_vae_f16.ckpt",
      "text_encoder": "open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "SD3 Large Turbo 3.5",
      "file": "sd3_large_turbo_3.5_q8p.ckpt",
      "version": "sd3_large",
      "default_scale": 16,
      "autoencoder": "sd3_vae_f16.ckpt",
      "text_encoder": "open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "SD3 Large Turbo 3.5 (6-bit)",
      "file": "sd3_large_turbo_3.5_q6p.ckpt",
      "version": "sd3_large",
      "default_scale": 16,
      "autoencoder": "sd3_vae_f16.ckpt",
      "text_encoder": "open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "SD3 Medium",
      "file": "sd3_medium_f16.ckpt",
      "version": "sd3",
      "default_scale": 16,
      "autoencoder": "sd3_vae_f16.ckpt",
      "text_encoder": "open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "SD3 Medium (8-bit)",
      "file": "sd3_medium_q8p.ckpt",
      "version": "sd3",
      "default_scale": 16,
      "autoencoder": "sd3_vae_f16.ckpt",
      "text_encoder": "open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "SD3 Medium 3.5",
      "file": "sd3_medium_3.5_f16.ckpt",
      "version": "sd3",
      "default_scale": 16,
      "autoencoder": "sd3_vae_f16.ckpt",
      "text_encoder": "open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "SD3 Medium 3.5 (8-bit)",
      "file": "sd3_medium_3.5_q8p.ckpt",
      "version": "sd3",
      "default_scale": 16,
      "autoencoder": "sd3_vae_f16.ckpt",
      "text_encoder": "open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "SDXL Turbo",
      "file": "sd_xl_turbo_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "default_scale": 8,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "SDXL Turbo (8-bit)",
      "file": "sd_xl_turbo_q6p_q8p.ckpt",
      "version": "sdxl_base_v0.9",
      "default_scale": 8,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "seek.art MEGA (v1)",
      "file": "seek_art_mega_v1_f16.ckpt",
      "version": "v1",
      "default_scale": 10,
      "text_encoder": "seek_art_mega_v1_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Shuttle Jaguar",
      "file": "shuttle_jaguar_q8p.ckpt",
      "version": "flux1",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Shuttle Jaguar (5-bit, SVDQuant)",
      "file": "shuttle_jaguar_q5p_svd.ckpt",
      "version": "flux1",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Shuttle v3.1 Aesthetic",
      "file": "shuttle_v3.1_aesthetic_q8p.ckpt",
      "version": "flux1",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Shuttle v3.1 Aesthetic (5-bit, SVDQuant)",
      "file": "shuttle_v3.1_aesthetic_q5p_svd.ckpt",
      "version": "flux1",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "SkyReels v1 Hunyuan I2V 544p",
      "file": "skyreels_v1_hunyuan_i2v_q8p.ckpt",
      "version": "hunyuan_video",
      "prefix": "FPS-24, ",
      "modifier": "inpainting",
      "note": "[SkyReels v1](https://huggingface.co/collections/Skywork/skyreels-v1-67b34676ff65b4ec02d16307) is a significant fine-tune of Hunyuan Video, Tencent\u2019s state-of-the-art text-to-video model. SkyReels v1 I2V is an image-to-video (img2vid) fine-tune that generates video clips up to 4 seconds long from a single image. The model supports up to 97 frames, with a recommended shift value of 7.0 or higher. For optimal results, disable \"Speedup w/ Guidance Embed\" by setting it to 1.0 and use a Text Guidance value of 6.",
      "default_scale": 12,
      "autoencoder": "hunyuan_video_vae_f16.ckpt",
      "text_encoder": "llava_llama_3_8b_v1.1_q8p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "SkyReels v1 Hunyuan I2V 544p (5-bit, SVDQuant)",
      "file": "skyreels_v1_hunyuan_i2v_q5p_svd.ckpt",
      "version": "hunyuan_video",
      "prefix": "FPS-24, ",
      "modifier": "inpainting",
      "note": "[SkyReels v1](https://huggingface.co/collections/Skywork/skyreels-v1-67b34676ff65b4ec02d16307) is a significant fine-tune of Hunyuan Video, Tencent\u2019s state-of-the-art text-to-video model. SkyReels v1 I2V is an image-to-video (img2vid) fine-tune that generates video clips up to 4 seconds long from a single image. The model supports up to 97 frames, with a recommended shift value of 7.0 or higher. For optimal results, disable \"Speedup w/ Guidance Embed\" by setting it to 1.0 and use a Text Guidance value of 6.",
      "default_scale": 12,
      "autoencoder": "hunyuan_video_vae_f16.ckpt",
      "text_encoder": "llava_llama_3_8b_v1.1_q8p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "SkyReels v1 Hunyuan T2V 544p",
      "file": "skyreels_v1_hunyuan_t2v_q8p.ckpt",
      "version": "hunyuan_video",
      "prefix": "FPS-24, ",
      "note": "[SkyReels v1](https://huggingface.co/collections/Skywork/skyreels-v1-67b34676ff65b4ec02d16307) is a significant fine-tune of Hunyuan Video, Tencent\u2019s state-of-the-art text-to-video model. It can generate video clips up to 4 seconds long at a recommended resolution of 960\u00d7544. The model supports up to 97 frames, with a recommended shift value of 7.0 or higher. For optimal results, disable \"Speedup w/ Guidance Embed\" by setting it to 1.0 and use a Text Guidance value of 6.",
      "default_scale": 12,
      "autoencoder": "hunyuan_video_vae_f16.ckpt",
      "text_encoder": "llava_llama_3_8b_v1.1_q8p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "SkyReels v1 Hunyuan T2V 544p (5-bit, SVDQuant)",
      "file": "skyreels_v1_hunyuan_t2v_q5p_svd.ckpt",
      "version": "hunyuan_video",
      "prefix": "FPS-24, ",
      "note": "[SkyReels v1](https://huggingface.co/collections/Skywork/skyreels-v1-67b34676ff65b4ec02d16307) is a significant fine-tune of Hunyuan Video, Tencent\u2019s state-of-the-art text-to-video model. It can generate video clips up to 4 seconds long at a recommended resolution of 960\u00d7544. The model supports up to 97 frames, with a recommended shift value of 7.0 or higher. For optimal results, disable \"Speedup w/ Guidance Embed\" by setting it to 1.0 and use a Text Guidance value of 6.",
      "default_scale": 12,
      "autoencoder": "hunyuan_video_vae_f16.ckpt",
      "text_encoder": "llava_llama_3_8b_v1.1_q8p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "SkyReels v2 I2V 1.3B 540p",
      "file": "skyreels_v2_i2v_1.3b_540p_f16.ckpt",
      "version": "wan_v2.1_1.3b",
      "modifier": "inpainting",
      "note": "[SkyReels v2 I2V 1.3B 540p](https://huggingface.co/Skywork/SkyReels-V2-I2V-1.3B-540P) is a image-to-video model developed by Skywork AI. It can generate video clips of up to 4 seconds in length. The model is trained at 544x960, supports up to 97 frames, with a recommended shift value of 5.0. As a derivative of Wan 2.1 (1.3B), it performs best with similar generation settings.",
      "default_scale": 8,
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "SkyReels v2 I2V 1.3B 540p (8-bit)",
      "file": "skyreels_v2_i2v_1.3b_540p_q8p.ckpt",
      "version": "wan_v2.1_1.3b",
      "modifier": "inpainting",
      "note": "[SkyReels v2 I2V 1.3B 540p](https://huggingface.co/Skywork/SkyReels-V2-I2V-1.3B-540P) is a image-to-video model developed by Skywork AI. It can generate video clips of up to 4 seconds in length. The model is trained at 544x960, supports up to 97 frames, with a recommended shift value of 5.0. As a derivative of Wan 2.1 (1.3B), it performs best with similar generation settings.",
      "default_scale": 8,
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "SkyReels v2 I2V 14B 540p",
      "file": "skyreels_v2_i2v_14b_540p_q8p.ckpt",
      "version": "wan_v2.1_14b",
      "modifier": "inpainting",
      "note": "[SkyReels v2 I2V 14B 540p](https://huggingface.co/Skywork/SkyReels-V2-I2V-14B-540P) is a image-to-video model developed by Skywork AI. It can generate video clips of up to 4 seconds in length. The model is trained at 544x960, supports up to 97 frames, with a recommended shift value of 5.0. As a derivative of Wan 2.1 (14B), it performs best with similar generation settings.",
      "default_scale": 12,
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "SkyReels v2 I2V 14B 540p (6-bit, SVDQuant)",
      "file": "skyreels_v2_i2v_14b_540p_q6p_svd.ckpt",
      "version": "wan_v2.1_14b",
      "modifier": "inpainting",
      "note": "[SkyReels v2 I2V 14B 540p](https://huggingface.co/Skywork/SkyReels-V2-I2V-14B-540P) is a image-to-video model developed by Skywork AI. It can generate video clips of up to 4 seconds in length. The model is trained at 544x960, supports up to 97 frames, with a recommended shift value of 5.0. As a derivative of Wan 2.1 (14B), it performs best with similar generation settings.",
      "default_scale": 12,
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "SkyReels v2 I2V 14B 720p",
      "file": "skyreels_v2_i2v_14b_720p_q8p.ckpt",
      "version": "wan_v2.1_14b",
      "modifier": "inpainting",
      "note": "[SkyReels v2 I2V 14B 720p](https://huggingface.co/Skywork/SkyReels-V2-I2V-14B-720P) is a image-to-video model developed by Skywork AI. It can generate video clips of up to 5 seconds in length. The model is trained at 720x1280, supports up to 121 frames, with a recommended shift value of 5.0. As a derivative of Wan 2.1 (14B), it performs best with similar generation settings.",
      "default_scale": 12,
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "SkyReels v2 I2V 14B 720p (6-bit, SVDQuant)",
      "file": "skyreels_v2_i2v_14b_720p_q6p_svd.ckpt",
      "version": "wan_v2.1_14b",
      "modifier": "inpainting",
      "note": "[SkyReels v2 I2V 14B 720p](https://huggingface.co/Skywork/SkyReels-V2-I2V-14B-720P) is a image-to-video model developed by Skywork AI. It can generate video clips of up to 5 seconds in length. The model is trained at 720x1280, supports up to 121 frames, with a recommended shift value of 5.0. As a derivative of Wan 2.1 (14B), it performs best with similar generation settings.",
      "default_scale": 12,
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "SkyReels v2 T2V 14B 540p",
      "file": "skyreels_v2_t2v_14b_540p_q8p.ckpt",
      "version": "wan_v2.1_14b",
      "note": "[SkyReels v2 T2V 14B 540p](https://huggingface.co/Skywork/SkyReels-V2-T2V-14B-540P) is a text-to-video model developed by Skywork AI. It can generate video clips of up to 4 seconds in length. The model is trained at 544x960, supports up to 97 frames, with a recommended shift value of 5.0. As a derivative of Wan 2.1 (14B), it performs best with similar generation settings.",
      "default_scale": 12,
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "upcast_attention": false
    },
    {
      "name": "SkyReels v2 T2V 14B 540p (6-bit, SVDQuant)",
      "file": "skyreels_v2_t2v_14b_540p_q6p_svd.ckpt",
      "version": "wan_v2.1_14b",
      "note": "[SkyReels v2 T2V 14B 540p](https://huggingface.co/Skywork/SkyReels-V2-T2V-14B-540P) is a text-to-video model developed by Skywork AI. It can generate video clips of up to 4 seconds in length. The model is trained at 544x960, supports up to 97 frames, with a recommended shift value of 5.0. As a derivative of Wan 2.1 (14B), it performs best with similar generation settings.",
      "default_scale": 12,
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "upcast_attention": false
    },
    {
      "name": "SkyReels v2 T2V 14B 720p",
      "file": "skyreels_v2_t2v_14b_720p_q8p.ckpt",
      "version": "wan_v2.1_14b",
      "note": "[SkyReels v2 T2V 14B 720p](https://huggingface.co/Skywork/SkyReels-V2-T2V-14B-720P) is a text-to-video model developed by Skywork AI. It can generate video clips of up to 5 seconds in length. The model is trained at 720x1280, supports up to 121 frames, with a recommended shift value of 5.0. As a derivative of Wan 2.1 (14B), it performs best with similar generation settings.",
      "default_scale": 12,
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "upcast_attention": false
    },
    {
      "name": "SkyReels v2 T2V 14B 720p (6-bit, SVDQuant)",
      "file": "skyreels_v2_t2v_14b_720p_q6p_svd.ckpt",
      "version": "wan_v2.1_14b",
      "note": "[SkyReels v2 T2V 14B 720p](https://huggingface.co/Skywork/SkyReels-V2-T2V-14B-720P) is a text-to-video model developed by Skywork AI. It can generate video clips of up to 5 seconds in length. The model is trained at 720x1280, supports up to 121 frames, with a recommended shift value of 5.0. As a derivative of Wan 2.1 (14B), it performs best with similar generation settings.",
      "default_scale": 12,
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Spider-Verse (v1)",
      "file": "spiderverse_v1_f16.ckpt",
      "version": "v1",
      "prefix": "spiderverse style ",
      "default_scale": 8,
      "text_encoder": "spiderverse_v1_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "SSD 1B (Segmind SDXL)",
      "file": "ssd_1b_f16.ckpt",
      "version": "ssd_1b",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "SSD 1B (Segmind SDXL) (8-bit)",
      "file": "ssd_1b_q6p_q8p.ckpt",
      "version": "ssd_1b",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Stable Cascade (W\u00fcrstchen v3.0)",
      "file": "wurstchen_3.0_stage_c_f32_f16.ckpt",
      "version": "wurstchen_v3.0_stage_c",
      "default_scale": 16,
      "autoencoder": "wurstchen_3.0_stage_a_hq_f16.ckpt",
      "text_encoder": "open_clip_vit_bigg14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Stable Cascade (W\u00fcrstchen v3.0) (8-bit)",
      "file": "wurstchen_3.0_stage_c_f32_q6p_q8p.ckpt",
      "version": "wurstchen_v3.0_stage_c",
      "default_scale": 16,
      "autoencoder": "wurstchen_3.0_stage_a_hq_f16.ckpt",
      "text_encoder": "open_clip_vit_bigg14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Stable Video Diffusion I2V v1.0",
      "file": "svd_i2v_1.0_f16.ckpt",
      "version": "svd_i2v",
      "modifier": "none",
      "default_scale": 8,
      "text_encoder": "open_clip_vit_h14_vision_model_f16.ckpt",
      "clip_encoder": "svd_i2v_1.0_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Stable Video Diffusion I2V v1.0 (8-bit)",
      "file": "svd_i2v_1.0_q6p_q8p.ckpt",
      "version": "svd_i2v",
      "modifier": "none",
      "default_scale": 8,
      "text_encoder": "open_clip_vit_h14_vision_model_f16.ckpt",
      "clip_encoder": "svd_i2v_1.0_q6p_q8p.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Stable Video Diffusion I2V XT v1.1",
      "file": "svd_i2v_xt_1.1_f16.ckpt",
      "version": "svd_i2v",
      "modifier": "none",
      "default_scale": 8,
      "text_encoder": "open_clip_vit_h14_vision_model_f16.ckpt",
      "clip_encoder": "svd_i2v_xt_1.1_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Stable Video Diffusion I2V XT v1.1 (8-bit)",
      "file": "svd_i2v_xt_1.1_q6p_q8p.ckpt",
      "version": "svd_i2v",
      "modifier": "none",
      "default_scale": 8,
      "text_encoder": "open_clip_vit_h14_vision_model_f16.ckpt",
      "clip_encoder": "svd_i2v_xt_1.1_q6p_q8p.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Super Mario Nation (v2)",
      "file": "supermarionation_v2_f16.ckpt",
      "version": "v1",
      "prefix": "supermarionation ",
      "default_scale": 8,
      "text_encoder": "supermarionation_v2_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Tron Legacy",
      "file": "trnlgcy_f16.ckpt",
      "version": "v1",
      "prefix": "trnlgcy style ",
      "default_scale": 8,
      "text_encoder": "trnlgcy_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Van Gogh Style (Lvngvncnt v2)",
      "file": "lvngvncnt_v2_f16.ckpt",
      "version": "v1",
      "prefix": "lvngvncnt ",
      "default_scale": 8,
      "text_encoder": "lvngvncnt_v2_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "VoxelArt (v1)",
      "file": "voxelart_v1_f16.ckpt",
      "version": "v1",
      "prefix": "voxelart ",
      "default_scale": 8,
      "text_encoder": "voxelart_v1_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Wan 2.1 1.3B Fun InP",
      "file": "wan_2.1_1.3b_fun_inp_f16.ckpt",
      "version": "wan_v2.1_1.3b",
      "modifier": "inpainting",
      "note": "[Wan2.1 1.3B Fun InP](https://huggingface.co/alibaba-pai/Wan2.1-Fun-1.3B-InP) is a state-of-the-art image-to-video model developed by Alibaba PAI. It can generate video clips of up to 4 seconds in length. The model is trained at multiple resolutions, supports up to 81 frames, with a recommended shift value of 5.0. Text Guidance should be somewhere between 3 to 7. Wan2.1 is trained with Flow Matching objective, Trailing samplers would give the best result.",
      "default_scale": 8,
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Wan 2.1 1.3B Fun InP (8-bit)",
      "file": "wan_2.1_1.3b_fun_inp_q8p.ckpt",
      "version": "wan_v2.1_1.3b",
      "modifier": "inpainting",
      "note": "[Wan2.1 1.3B Fun InP](https://huggingface.co/alibaba-pai/Wan2.1-Fun-1.3B-InP) is a state-of-the-art image-to-video model developed by Alibaba PAI. It can generate video clips of up to 4 seconds in length. The model is trained at multiple resolutions, supports up to 81 frames, with a recommended shift value of 5.0. Text Guidance should be somewhere between 3 to 7. Wan2.1 is trained with Flow Matching objective, Trailing samplers would give the best result.",
      "default_scale": 8,
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Wan 2.1 1.3B v1.1 Fun InP",
      "file": "wan_2.1_1.3b_v1.1_fun_inp_f16.ckpt",
      "version": "wan_v2.1_1.3b",
      "modifier": "inpainting",
      "note": "[Wan2.1 1.3B v1.1 Fun InP](https://huggingface.co/alibaba-pai/Wan2.1-Fun-V1.1-1.3B-InP) is a state-of-the-art image-to-video model developed by Alibaba PAI. It can generate video clips of up to 4 seconds in length. The model is trained at multiple resolutions, supports up to 81 frames, with a recommended shift value of 5.0. Text Guidance should be somewhere between 3 to 7. Wan2.1 is trained with Flow Matching objective, Trailing samplers would give the best result.",
      "default_scale": 8,
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Wan 2.1 1.3B v1.1 Fun InP (8-bit)",
      "file": "wan_2.1_1.3b_v1.1_fun_inp_q8p.ckpt",
      "version": "wan_v2.1_1.3b",
      "modifier": "inpainting",
      "note": "[Wan2.1 1.3B v1.1 Fun InP](https://huggingface.co/alibaba-pai/Wan2.1-Fun-V1.1-1.3B-InP) is a state-of-the-art image-to-video model developed by Alibaba PAI. It can generate video clips of up to 4 seconds in length. The model is trained at multiple resolutions, supports up to 81 frames, with a recommended shift value of 5.0. Text Guidance should be somewhere between 3 to 7. Wan2.1 is trained with Flow Matching objective, Trailing samplers would give the best result.",
      "default_scale": 8,
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Wan 2.1 14B Fun InP",
      "file": "wan_2.1_14b_fun_inp_q8p.ckpt",
      "version": "wan_v2.1_14b",
      "modifier": "inpainting",
      "note": "[Wan2.1 14B Fun InP](https://huggingface.co/alibaba-pai/Wan2.1-Fun-14B-InP) is a state-of-the-art image-to-video model developed by Alibaba PAI. It can generate video clips of up to 4 seconds in length. The model is trained at multiple resolutions, supports up to 81 frames, with a recommended shift value of 5.0. Text Guidance should be somewhere between 3 to 7. Wan2.1 is trained with Flow Matching objective, Trailing samplers would give the best result.",
      "default_scale": 12,
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Wan 2.1 14B Fun InP (6-bit, SVDQuant)",
      "file": "wan_2.1_14b_fun_inp_q6p_svd.ckpt",
      "version": "wan_v2.1_14b",
      "modifier": "inpainting",
      "note": "[Wan2.1 14B Fun InP](https://huggingface.co/alibaba-pai/Wan2.1-Fun-14B-InP) is a state-of-the-art image-to-video model developed by Alibaba PAI. It can generate video clips of up to 4 seconds in length. The model is trained at multiple resolutions, supports up to 81 frames, with a recommended shift value of 5.0. Text Guidance should be somewhere between 3 to 7. Wan2.1 is trained with Flow Matching objective, Trailing samplers would give the best result.",
      "default_scale": 12,
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Wan 2.1 14B I2V FusionX",
      "file": "wan_2.1_14b_i2v_fusionx_q8p.ckpt",
      "version": "wan_v2.1_14b",
      "modifier": "inpainting",
      "note": "[Wan2.1 14B FusionX](https://huggingface.co/vrgamedevgirl84/Wan14BT2VFusioniX) is a merged model of multiple quality and acceleration LoRAs.",
      "default_scale": 12,
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Wan 2.1 14B I2V FusionX (6-bit, SVDQuant)",
      "file": "wan_2.1_14b_i2v_fusionx_q6p_svd.ckpt",
      "version": "wan_v2.1_14b",
      "modifier": "inpainting",
      "note": "[Wan2.1 14B FusionX](https://huggingface.co/vrgamedevgirl84/Wan14BT2VFusioniX) is a merged model of multiple quality and acceleration LoRAs.",
      "default_scale": 12,
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Wan 2.1 14B T2V FusionX",
      "file": "wan_2.1_14b_t2v_fusionx_q8p.ckpt",
      "version": "wan_v2.1_14b",
      "note": "[Wan2.1 14B FusionX](https://huggingface.co/vrgamedevgirl84/Wan14BT2VFusioniX) is a merged model of multiple quality and acceleration LoRAs.",
      "default_scale": 12,
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Wan 2.1 14B T2V FusionX (6-bit, SVDQuant)",
      "file": "wan_2.1_14b_t2v_fusionx_q6p_svd.ckpt",
      "version": "wan_v2.1_14b",
      "note": "[Wan2.1 14B FusionX](https://huggingface.co/vrgamedevgirl84/Wan14BT2VFusioniX) is a merged model of multiple quality and acceleration LoRAs.",
      "default_scale": 12,
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Wan 2.1 14B v1.1 Fun InP",
      "file": "wan_2.1_14b_v1.1_fun_inp_q8p.ckpt",
      "version": "wan_v2.1_14b",
      "modifier": "inpainting",
      "note": "[Wan2.1 14B v1.1 Fun InP](https://huggingface.co/alibaba-pai/Wan2.1-Fun-V1.1-14B-InP) is a state-of-the-art image-to-video model developed by Alibaba PAI. It can generate video clips of up to 4 seconds in length. The model is trained at multiple resolutions, supports up to 81 frames, with a recommended shift value of 5.0. Text Guidance should be somewhere between 3 to 7. Wan2.1 is trained with Flow Matching objective, Trailing samplers would give the best result.",
      "default_scale": 12,
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Wan 2.1 14B v1.1 Fun InP (6-bit, SVDQuant)",
      "file": "wan_2.1_14b_v1.1_fun_inp_q6p_svd.ckpt",
      "version": "wan_v2.1_14b",
      "modifier": "inpainting",
      "note": "[Wan2.1 14B v1.1 Fun InP](https://huggingface.co/alibaba-pai/Wan2.1-Fun-V1.1-14B-InP) is a state-of-the-art image-to-video model developed by Alibaba PAI. It can generate video clips of up to 4 seconds in length. The model is trained at multiple resolutions, supports up to 81 frames, with a recommended shift value of 5.0. Text Guidance should be somewhere between 3 to 7. Wan2.1 is trained with Flow Matching objective, Trailing samplers would give the best result.",
      "default_scale": 12,
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Wan v2.2 High Noise Expert T2V A14B Lightning 250928",
      "file": "wan_v2.2_a14b_hne_t2v_lightning_250928_q8p.ckpt",
      "version": "wan_v2.1_14b",
      "note": "[Wan2.2 High Noise Expert T2V A14B Lightning 250928](https://huggingface.co/lightx2v/Wan2.2-Lightning/tree/main/Wan2.2-T2V-A14B-4steps-250928-dyno) is a fine-tune of Wan v2.2 High Noise Expert model. It can generate more dynamic motions with 4 steps and text guidance 1.0.",
      "default_scale": 12,
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Wan v2.2 High Noise Expert T2V A14B Lightning 250928 (6-bit, SVDQuant)",
      "file": "wan_v2.2_a14b_hne_t2v_lightning_250928_q6p_svd.ckpt",
      "version": "wan_v2.1_14b",
      "note": "[Wan2.2 High Noise Expert T2V A14B Lightning 250928](https://huggingface.co/lightx2v/Wan2.2-Lightning/tree/main/Wan2.2-T2V-A14B-4steps-250928-dyno) is a fine-tune of Wan v2.2 High Noise Expert model. It can generate more dynamic motions with 4 steps and text guidance 1.0.",
      "default_scale": 12,
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "upcast_attention": false
    },
    {
      "name": "Z Image Turbo 1.0 (Exact)",
      "file": "z_image_turbo_1.0_f16.ckpt",
      "version": "z_image",
      "note": "[Z Image Turbo](https://huggingface.co/Tongyi-MAI/Z-Image-Turbo) is is a powerful and highly efficient image generation model with 6B parameters. It is Apache 2.0-licensed and commercially friendly. The model is trained at multiple resolutions using a Flow Matching objective; trailing samplers yield the best results, with 8 sampling steps recommended.",
      "default_scale": 16,
      "autoencoder": "flux_1_vae_f16.ckpt",
      "text_encoder": "qwen_3_vl_4b_instruct_f16.ckpt",
      "upcast_attention": false
    }
  ],
  "loras": [
    {
      "name": "360 Degree [dev]",
      "file": "360_degree__dev__lora_f16.ckpt",
      "version": "flux1"
    },
    {
      "name": "ACE++: Local Editing",
      "file": "ace____local_editing_lora_f16.ckpt",
      "version": "flux1"
    },
    {
      "name": "ACE++: Portrait",
      "file": "ace____portrait_lora_f16.ckpt",
      "version": "flux1"
    },
    {
      "name": "ACE++: Subject",
      "file": "ace____subject_lora_f16.ckpt",
      "version": "flux1"
    },
    {
      "name": "Adam's Artwork Style v.1",
      "file": "adams_artwork_style_v0.1_lora_f16.ckpt",
      "version": "v1",
      "prefix": "ajaws "
    },
    {
      "name": "Add More Details (Detail Enhancer / Tweaker)",
      "file": "add_more_details__detail_enhancer___tweaker__lora_f16.ckpt",
      "version": "v1"
    },
    {
      "name": "Age Slider",
      "file": "age_slider_lora_f16.ckpt",
      "version": "sdxl_base_v0.9"
    },
    {
      "name": "Amateur Photography v3.5 [dev]",
      "file": "amateur_photography_v3.5__dev__lora_f16.ckpt",
      "version": "flux1"
    },
    {
      "name": "Analog Diffusion v1.0",
      "file": "analog_diffusion_v1_lora_f16.ckpt",
      "version": "v1",
      "prefix": "analog "
    },
    {
      "name": "Anime LineArt Style v2.0",
      "file": "anime_lineart_style_v2.0_lora_f16.ckpt",
      "version": "v1"
    },
    {
      "name": "AntiBlur v1.0 [dev]",
      "file": "antiblur_v1.0__dev__lora_f16.ckpt",
      "version": "flux1"
    },
    {
      "name": "Arcane Style",
      "file": "arcane_style_lora_f16.ckpt",
      "version": "v1",
      "prefix": "arcane style "
    },
    {
      "name": "Boring Reality v2 [dev]",
      "file": "boring_reality_v2_lora_f16.ckpt",
      "version": "flux1"
    },
    {
      "name": "CCXL-Mucha Art Style",
      "file": "ccxl_mucha_art_style_lora_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "prefix": "ccxl-mucha "
    },
    {
      "name": "ChronoEdit 14B Step Distill",
      "file": "chronoedit_14b_step_distill_lora_f16.ckpt",
      "version": "wan_v2.1_14b"
    },
    {
      "name": "ChronoEdit 14B Upsample",
      "file": "chronoedit_14b_upsample_lora_f16.ckpt",
      "version": "wan_v2.1_14b"
    },
    {
      "name": "Crazy Expressions",
      "file": "crazy_expressions_lora_f16.ckpt",
      "version": "v1",
      "prefix": "crazy face "
    },
    {
      "name": "Cyberpunk 2077 Nightcity v1.15",
      "file": "cyberpunk_2007_concept_art_nightcity_v1.15_lora_f16.ckpt",
      "version": "v1"
    },
    {
      "name": "DMD2 SDXL 4-Step",
      "file": "dmd2_sdxl_4_step_lora_f16.ckpt",
      "version": "sdxl_base_v0.9"
    },
    {
      "name": "Epi Noise Offset v2",
      "file": "epi_noiseoffset_v2_lora_f16.ckpt",
      "version": "v1"
    },
    {
      "name": "Fix Hands Slider",
      "file": "fix_hands_slider_lora_f16.ckpt",
      "version": "sdxl_base_v0.9"
    },
    {
      "name": "FLUX.1 [dev] to [schnell] 4-Step",
      "file": "flux.1__dev__to__schnell__4_step_lora_f16.ckpt",
      "version": "flux1"
    },
    {
      "name": "FLUX.1 Canny [dev]",
      "file": "flux_1_canny_dev_lora_f16.ckpt",
      "version": "flux1"
    },
    {
      "name": "FLUX.1 Depth [dev]",
      "file": "flux_1_depth_dev_lora_f16.ckpt",
      "version": "flux1"
    },
    {
      "name": "FLUX.1 Turbo Alpha",
      "file": "flux.1_turbo_alpha_lora_f16.ckpt",
      "version": "flux1"
    },
    {
      "name": "Ghibli Cartoon Art",
      "file": "ghibli_cartoon_art_lora_f16.ckpt",
      "version": "flux1",
      "prefix": "Ghibli Art"
    },
    {
      "name": "Haute Couture or Gowns v1.0",
      "file": "haute_couture_or_gowns_v1.0_lora_f16.ckpt",
      "version": "v1",
      "prefix": "hc_gown "
    },
    {
      "name": "HiDream E1",
      "file": "hidream_e1_full_lora_f16.ckpt",
      "version": "hidream_i1"
    },
    {
      "name": "Hipoly 3D Model",
      "file": "hipoly_3d_model_lora_f16.ckpt",
      "version": "v1",
      "prefix": "hiqcgbody "
    },
    {
      "name": "Hyper FLUX.1 [dev] 16-Step",
      "file": "hyper_flux.1__dev__16_step_lora_f16.ckpt",
      "version": "flux1"
    },
    {
      "name": "Hyper FLUX.1 [dev] 8-Step",
      "file": "hyper_flux.1__dev__8_step_lora_f16.ckpt",
      "version": "flux1"
    },
    {
      "name": "Hyper SD v1.x 4-Step",
      "file": "hyper_sd_v1.x_4_step_lora_f16.ckpt",
      "version": "v1",
      "is_consistency_model": true
    },
    {
      "name": "Hyper SD v1.x 8-Step",
      "file": "hyper_sd_v1.x_8_step_lora_f16.ckpt",
      "version": "v1",
      "is_consistency_model": true
    },
    {
      "name": "Hyper SD3 16-Step CFG",
      "file": "hyper_sd3_16_step_cfg_lora_f16.ckpt",
      "version": "sd3"
    },
    {
      "name": "Hyper SD3 4-Step CFG",
      "file": "hyper_sd3_4_step_cfg_lora_f16.ckpt",
      "version": "sd3"
    },
    {
      "name": "Hyper SD3 8-Step CFG",
      "file": "hyper_sd3_8_step_cfg_lora_f16.ckpt",
      "version": "sd3"
    },
    {
      "name": "Hyper SDXL 4-Step",
      "file": "hyper_sdxl_4_step_lora_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "is_consistency_model": true
    },
    {
      "name": "Hyper SDXL 8-Step",
      "file": "hyper_sdxl_8_step_lora_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "is_consistency_model": true
    },
    {
      "name": "ICEdit Normal",
      "file": "icedit_normal_lora_f16.ckpt",
      "version": "flux1"
    },
    {
      "name": "In-Context: Couple Profile",
      "file": "in_context__couple_profile_lora_f16.ckpt",
      "version": "flux1"
    },
    {
      "name": "In-Context: Film Storyboard",
      "file": "in_context__film_storyboard_lora_f16.ckpt",
      "version": "flux1"
    },
    {
      "name": "In-Context: Font Design",
      "file": "in_context__font_design_lora_f16.ckpt",
      "version": "flux1"
    },
    {
      "name": "In-Context: Home Decoration",
      "file": "in_context__home_decoration_lora_f16.ckpt",
      "version": "flux1"
    },
    {
      "name": "In-Context: Portrait Illustration",
      "file": "in_context__portrait_illustration_lora_f16.ckpt",
      "version": "flux1"
    },
    {
      "name": "In-Context: Portrait Photography",
      "file": "in_context__portrait_photography_lora_f16.ckpt",
      "version": "flux1"
    },
    {
      "name": "In-Context: PPT Templates",
      "file": "in_context__ppt_templates_lora_f16.ckpt",
      "version": "flux1"
    },
    {
      "name": "In-Context: Visual Identity Design",
      "file": "in_context__visual_identity_design_lora_f16.ckpt",
      "version": "flux1"
    },
    {
      "name": "LCM SSD 1B (Segmind)",
      "file": "lcm_ssd_1b_lora_f16.ckpt",
      "version": "ssd_1b"
    },
    {
      "name": "Long Hair Slider",
      "file": "long_hair_slider_lora_f16.ckpt",
      "version": "sdxl_base_v0.9"
    },
    {
      "name": "Mascular Slider",
      "file": "mascular_slider_lora_f16.ckpt",
      "version": "sdxl_base_v0.9"
    },
    {
      "name": "Moxin Shukezouma v1.1",
      "file": "moxin_shukezouma_v1.1_lora_f16.ckpt",
      "version": "v1",
      "prefix": "shukezouma "
    },
    {
      "name": "Moxin v1.0",
      "file": "moxin_v1.0_lora_f16.ckpt",
      "version": "v1",
      "prefix": "shuimobysim "
    },
    {
      "name": "Object Removal for FLUX.1 Fill v2",
      "file": "object_removal_for_flux.1_fill_v2_lora_f16.ckpt",
      "version": "flux1"
    },
    {
      "name": "Openjourney v1.0",
      "file": "openjourney_v1_lora_f16.ckpt",
      "version": "v1",
      "prefix": "mdjrny-v4 "
    },
    {
      "name": "Papercut SDXL",
      "file": "papercut_sdxl_lora_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "prefix": "papercut "
    },
    {
      "name": "PCM SD3 4-Step",
      "file": "pcm_sd3_4_step_lora_f16.ckpt",
      "version": "sd3"
    },
    {
      "name": "Pixel Art XL v1.1",
      "file": "pixel_art_xl_v1.1_lora_f16.ckpt",
      "version": "sdxl_base_v0.9"
    },
    {
      "name": "Pony: People\u2019s Works v8_Illusv 2.0 Stable",
      "file": "pony__people_s_works_v8_illusv_2.0_stable_lora_f16.ckpt",
      "version": "sdxl_base_v0.9"
    },
    {
      "name": "Qwen Edit 2509 Anything2Real",
      "file": "qwen_edit_2509_anything2real_lora_f16.ckpt",
      "version": "qwen_image"
    },
    {
      "name": "Qwen Edit 2509 Fusion",
      "file": "qwen_edit_2509_fusion_lora_f16.ckpt",
      "version": "qwen_image"
    },
    {
      "name": "Qwen Edit 2509 Multiple Angles",
      "file": "qwen_edit_2509_multiple_angles_lora_f16.ckpt",
      "version": "qwen_image"
    },
    {
      "name": "Qwen Edit 2509 Relight",
      "file": "qwen_edit_2509_relight_lora_f16.ckpt",
      "version": "qwen_image"
    },
    {
      "name": "Qwen Edit 2509 White to Scene",
      "file": "qwen_edit_2509_white_to_scene_lora_f16.ckpt",
      "version": "qwen_image"
    },
    {
      "name": "Qwen Image 1.0 Lightning 4-Step v1.0",
      "file": "qwen_image_1.0_lightning_4_step_v1.0_lora_f16.ckpt",
      "version": "qwen_image"
    },
    {
      "name": "Qwen Image 1.0 Lightning 4-Step v2.0",
      "file": "qwen_image_1.0_lightning_4_step_v2.0_lora_f16.ckpt",
      "version": "qwen_image"
    },
    {
      "name": "Qwen Image 1.0 Lightning 8-Step v1.1",
      "file": "qwen_image_1.0_lightning_8_step_v1.1_lora_f16.ckpt",
      "version": "qwen_image"
    },
    {
      "name": "Qwen Image 1.0 Lightning 8-Step v2.0",
      "file": "qwen_image_1.0_lightning_8_step_v2.0_lora_f16.ckpt",
      "version": "qwen_image"
    },
    {
      "name": "Qwen Image Edit 1.0 Lightning 4-Step v1.0",
      "file": "qwen_image_edit_1.0_lightning_4_step_v1.0_lora_f16.ckpt",
      "version": "qwen_image"
    },
    {
      "name": "Qwen Image Edit 1.0 Lightning 8-Step v1.0",
      "file": "qwen_image_edit_1.0_lightning_8_step_v1.0_lora_f16.ckpt",
      "version": "qwen_image"
    },
    {
      "name": "Qwen Image Edit 2509 Lightning 4-Step v1.0",
      "file": "qwen_image_edit_2509_lightning_4_step_v1.0_lora_f16.ckpt",
      "version": "qwen_image"
    },
    {
      "name": "Qwen Image Edit 2509 Lightning 8-Step v1.0",
      "file": "qwen_image_edit_2509_lightning_8_step_v1.0_lora_f16.ckpt",
      "version": "qwen_image"
    },
    {
      "name": "SD3 Medium 3.5 Turbo 4-Step",
      "file": "sd3_medium_3.5_turbo_4_step_lora_f16.ckpt",
      "version": "sd3"
    },
    {
      "name": "SD3 Medium 3.5 Turbo 8-Step",
      "file": "sd3_medium_3.5_turbo_8_step_lora_f16.ckpt",
      "version": "sd3"
    },
    {
      "name": "SDXL Lightning 4-Step",
      "file": "sdxl_lightning_4_step_lora_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "is_consistency_model": true
    },
    {
      "name": "SDXL Lightning 8-Step",
      "file": "sdxl_lightning_8_step_lora_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "is_consistency_model": true
    },
    {
      "name": "SDXL Render v2.0",
      "file": "sdxl_render_v2.0_lora_f16.ckpt",
      "version": "v1"
    },
    {
      "name": "Smiling Slider",
      "file": "smiling_slider_lora_f16.ckpt",
      "version": "sdxl_base_v0.9"
    },
    {
      "name": "Surprised Look Slider",
      "file": "surprised_look_slider_lora_f16.ckpt",
      "version": "sdxl_base_v0.9"
    },
    {
      "name": "Theovercomer8's Contrast Fix",
      "file": "theovercomer8s_contrast_fix_lora_f16.ckpt",
      "version": "v1",
      "prefix": "to8contrast style "
    },
    {
      "name": "Theovercomer8's Contrast Fix",
      "file": "theovercomer8s_contrast_fix_sd_v2.x_lora_f16.ckpt",
      "version": "v2",
      "prefix": "to8contrast style "
    },
    {
      "name": "TO8's High Key",
      "file": "to8s_high_key_lora_f16.ckpt",
      "version": "v1",
      "prefix": "to8highkey "
    },
    {
      "name": "TO8's High Key",
      "file": "to8s_high_key_sd_v2.x_lora_f16.ckpt",
      "version": "v2",
      "prefix": "to8highkey "
    },
    {
      "name": "Transparent Image FLUX.1 [dev]",
      "file": "layer_flux_1_transparent_lora_f16.ckpt",
      "version": "flux1"
    },
    {
      "name": "Wan 2.1 1.3B CausVid T2V",
      "file": "wan_2.1_1.3b_causvid_t2v_lora_f16.ckpt",
      "version": "wan_v2.1_1.3b"
    },
    {
      "name": "Wan 2.1 1.3B CFG Distill",
      "file": "wan_2.1_1.3b_cfg_distill_lora_f16.ckpt",
      "version": "wan_v2.1_1.3b",
      "is_consistency_model": true
    },
    {
      "name": "Wan 2.1 14B 480p Self-Forcing I2V",
      "file": "wan_2.1_14b_480p_self_forcing_i2v_lora_f16.ckpt",
      "version": "wan_v2.1_14b"
    },
    {
      "name": "Wan 2.1 14B CausVid T2V",
      "file": "wan_2.1_14b_causvid_t2v_lora_f16.ckpt",
      "version": "wan_v2.1_14b"
    },
    {
      "name": "Wan 2.1 14B Self-Forcing T2V",
      "file": "wan_2.1_14b_self_forcing_t2v_v2_lora_f16.ckpt",
      "version": "wan_v2.1_14b"
    },
    {
      "name": "Wan 2.2 A14B Lightning High Noise Expert I2V 251022",
      "file": "wan_v2.2_a14b_hne_i2v_lightning_251022_lora_f16.ckpt",
      "version": "wan_v2.1_14b"
    },
    {
      "name": "Wan 2.2 A14B Lightning High Noise Expert I2V v1.0",
      "file": "wan_v2.2_a14b_hne_i2v_lightning_v1.0_lora_f16.ckpt",
      "version": "wan_v2.1_14b"
    },
    {
      "name": "Wan 2.2 A14B Lightning High Noise Expert T2V v1.1",
      "file": "wan_v2.2_a14b_hne_t2v_lightning_v1.1_lora_f16.ckpt",
      "version": "wan_v2.1_14b"
    },
    {
      "name": "Wan 2.2 A14B Lightning High Noise Expert T2V v2.0",
      "file": "wan_v2.2_a14b_hne_t2v_lightning_v2.0_lora_f16.ckpt",
      "version": "wan_v2.1_14b"
    },
    {
      "name": "Wan 2.2 A14B Lightning Low Noise Expert I2V 251022",
      "file": "wan_v2.2_a14b_lne_i2v_lightning_251022_lora_f16.ckpt",
      "version": "wan_v2.1_14b"
    },
    {
      "name": "Wan 2.2 A14B Lightning Low Noise Expert I2V v1.0",
      "file": "wan_v2.2_a14b_lne_i2v_lightning_v1.0_lora_f16.ckpt",
      "version": "wan_v2.1_14b"
    },
    {
      "name": "Wan 2.2 A14B Lightning Low Noise Expert T2V 250928",
      "file": "wan_v2.2_a14b_lne_t2v_lightning_250928_lora_f16.ckpt",
      "version": "wan_v2.1_14b"
    },
    {
      "name": "Wan 2.2 A14B Lightning Low Noise Expert T2V v1.1",
      "file": "wan_v2.2_a14b_lne_t2v_lightning_v1.1_lora_f16.ckpt",
      "version": "wan_v2.1_14b"
    },
    {
      "name": "Wan 2.2 A14B Lightning Low Noise Expert T2V v2.0",
      "file": "wan_v2.2_a14b_lne_t2v_lightning_v2.0_lora_f16.ckpt",
      "version": "wan_v2.1_14b"
    },
    {
      "name": "Weight Slider",
      "file": "weight_slider_lora_f16.ckpt",
      "version": "sdxl_base_v0.9"
    }
  ],
  "controlNets": [
    {
      "name": "Alimam Inpaint Beta (FLUX.1 [dev], ControlNet)",
      "file": "controlnet_alimama_inpaint_flux_1_dev_beta_q8p.ckpt",
      "version": "flux1"
    },
    {
      "name": "Alimam Inpaint Beta (FLUX.1 [dev], ControlNet) (6-bit)",
      "file": "controlnet_alimama_inpaint_flux_1_dev_beta_q6p.ckpt",
      "version": "flux1"
    },
    {
      "name": "Canny Edge Map (Kwai Kolors 1.0)",
      "file": "controlnet_canny_kwai_kolors_1.0_f16.ckpt",
      "version": "sdxl_base_v0.9"
    },
    {
      "name": "Canny Edge Map (Kwai Kolors 1.0) (8-bit)",
      "file": "controlnet_canny_kwai_kolors_1.0_q6p_q8p.ckpt",
      "version": "sdxl_base_v0.9"
    },
    {
      "name": "Depth Map (Kwai Kolors 1.0)",
      "file": "controlnet_depth_kwai_kolors_1.0_f16.ckpt",
      "version": "sdxl_base_v0.9"
    },
    {
      "name": "Depth Map (Kwai Kolors 1.0) (8-bit)",
      "file": "controlnet_depth_kwai_kolors_1.0_q6p_q8p.ckpt",
      "version": "sdxl_base_v0.9"
    },
    {
      "name": "FLEX.1 Redux SigLIP2 512 (FLUX.1)",
      "file": "flex_1_redux_siglip2_512_f16.ckpt",
      "version": "flux1"
    },
    {
      "name": "FLUX.1 Redux (FLUX.1)",
      "file": "flux_1_redux_f16.ckpt",
      "version": "flux1"
    },
    {
      "name": "Garment UNet (Full-Body, Outfitting Fusion)",
      "file": "ootd_garm_full_body_1.0_f16.ckpt",
      "version": "v1"
    },
    {
      "name": "Garment UNet (Upper-Body, Outfitting Fusion)",
      "file": "ootd_garm_upper_body_1.0_f16.ckpt",
      "version": "v1"
    },
    {
      "name": "IP Adapter FaceID Plus (Kwai Kolors 1.0)",
      "file": "ip_adapter_faceid_plus_kwai_kolors_1.0_clip_l14_336_f16.ckpt",
      "version": "sdxl_base_v0.9"
    },
    {
      "name": "IP Adapter FaceID Plus (Kwai Kolors 1.0) (8-bit)",
      "file": "ip_adapter_faceid_plus_kwai_kolors_1.0_clip_l14_336_q8p.ckpt",
      "version": "sdxl_base_v0.9"
    },
    {
      "name": "IP Adapter Plus (Kwai Kolors 1.0)",
      "file": "ip_adapter_plus_kwai_kolors_1.0_clip_l14_336_f16.ckpt",
      "version": "sdxl_base_v0.9"
    },
    {
      "name": "Jasper AI Upscaler (FLUX.1 [dev], ControlNet)",
      "file": "controlnet_jasper_ai_upscaler_flux_1_dev_1.0_f16.ckpt",
      "version": "flux1"
    },
    {
      "name": "LLaVA Image Prompt (Hunyuan Video)",
      "file": "llava_llama_3_8b_v1.1_multi_modal_projector_f16.ckpt",
      "version": "hunyuan_video"
    },
    {
      "name": "Pose (Kwai Kolors 1.0)",
      "file": "controlnet_pose_kwai_kolors_1.0_f16.ckpt",
      "version": "sdxl_base_v0.9"
    },
    {
      "name": "Pose (Kwai Kolors 1.0) (8-bit)",
      "file": "controlnet_pose_kwai_kolors_1.0_q6p_q8p.ckpt",
      "version": "sdxl_base_v0.9"
    },
    {
      "name": "PuLID 0.9.1 (FLUX.1 [dev])",
      "file": "pulid_0.9.1_eva02_clip_l14_336_f16.ckpt",
      "version": "flux1"
    },
    {
      "name": "Union Pro (FLUX.1 [dev], ControlNet)",
      "file": "controlnet_union_pro_flux_1_dev_1.0_q8p.ckpt",
      "version": "flux1"
    },
    {
      "name": "Union Pro (FLUX.1 [dev], ControlNet) (5-bit)",
      "file": "controlnet_union_pro_flux_1_dev_1.0_q5p.ckpt",
      "version": "flux1"
    },
    {
      "name": "Union Pro 2.0 (FLUX.1 [dev], ControlNet)",
      "file": "controlnet_union_pro_flux_1_dev_2.0_q8p.ckpt",
      "version": "flux1"
    },
    {
      "name": "Union Pro 2.0 (FLUX.1 [dev], ControlNet) (5-bit)",
      "file": "controlnet_union_pro_flux_1_dev_2.0_q5p.ckpt",
      "version": "flux1"
    },
    {
      "name": "Xinsir Union ProMax (SDXL, ControlNet)",
      "file": "controlnet_xinsir_union_promax_sdxl_1.0_f16.ckpt",
      "version": "sdxl_base_v0.9"
    }
  ],
  "textualInversions": [
    {
      "name": "Action Helper",
      "file": "actionhelper_ti_f16.ckpt",
      "keyword": "actionhelper",
      "version": "v2",
      "length": 6
    },
    {
      "name": "Anime ScreenCap",
      "file": "animescreencap_ti_f16.ckpt",
      "keyword": "animescreencap",
      "version": "v2",
      "length": 6
    },
    {
      "name": "Bad Prompt (v2)",
      "file": "bad_prompt_v2_ti_f16.ckpt",
      "keyword": "bad_prompt",
      "version": "v1",
      "length": 8
    },
    {
      "name": "Birb Style",
      "file": "birb_style_ti_f16.ckpt",
      "keyword": "birb_style",
      "version": "v1",
      "length": 1
    },
    {
      "name": "Car Helper",
      "file": "carhelper_ti_f16.ckpt",
      "keyword": "carhelper",
      "version": "v2",
      "length": 4
    },
    {
      "name": "Character Turner v2",
      "file": "charturner_v2_ti_f16.ckpt",
      "keyword": "charturnerv2",
      "version": "v1",
      "length": 15
    },
    {
      "name": "Cinema Helper",
      "file": "cinemahelper_ti_f16.ckpt",
      "keyword": "cinemahelper",
      "version": "v2",
      "length": 10
    },
    {
      "name": "Classipeint",
      "file": "classipeint_ti_f16.ckpt",
      "keyword": "classipeint",
      "version": "v2",
      "length": 15
    },
    {
      "name": "Cloudport v1.0",
      "file": "cloudport_v1.0_ti_f16.ckpt",
      "keyword": "cloudport",
      "version": "v1",
      "length": 4
    },
    {
      "name": "Doctor Diffusion's \"Point E\" Negative Embedding",
      "file": "drd_point_e_768_v_ti_f16.ckpt",
      "keyword": "drd_pnte768",
      "version": "v2",
      "length": 8
    },
    {
      "name": "Double Exposure",
      "file": "double_exposure_ti_f16.ckpt",
      "keyword": "double_exposure",
      "version": "v2",
      "length": 8
    },
    {
      "name": "EasyNegative",
      "file": "easynegative_ti_f16.ckpt",
      "keyword": "easynegative",
      "version": "v1",
      "length": 8
    },
    {
      "name": "Fast Negative",
      "file": "fast_negative_ti_f16.ckpt",
      "keyword": "fastnegativev2",
      "version": "v1",
      "length": 67
    },
    {
      "name": "Knollingcase (v4)",
      "file": "knollingcase_v4_kc16_5000_ti_f16.ckpt",
      "keyword": "kc16_5000",
      "version": "v2",
      "length": 16
    },
    {
      "name": "Laxpeint (v2)",
      "file": "laxpeint_v2_ti_f16.ckpt",
      "keyword": "laxpeintv2",
      "version": "v2",
      "length": 9
    },
    {
      "name": "NegativeXL",
      "file": "negativexl_ti_f16.ckpt",
      "keyword": "negativexl_d",
      "version": "sdxl_base_v0.9",
      "length": 16
    },
    {
      "name": "ParchArt",
      "file": "parchart_ti_f16.ckpt",
      "keyword": "parchart",
      "version": "v2",
      "length": 10
    },
    {
      "name": "Photo Helper",
      "file": "photohelper_ti_f16.ckpt",
      "keyword": "photohelper",
      "version": "v2",
      "length": 8
    },
    {
      "name": "Pure Eros Face",
      "file": "pure_eros_ti_f16.ckpt",
      "keyword": "pure_eros",
      "version": "v1",
      "length": 1
    },
    {
      "name": "SD2 Papercut",
      "file": "sd2_papercut_ti_f16.ckpt",
      "keyword": "sd2_papercut",
      "version": "v2",
      "length": 8
    },
    {
      "name": "UnaestheticXL Alb2",
      "file": "unaestheticxl_alb2_ti_f16.ckpt",
      "keyword": "unaestheticxl_alb2",
      "version": "sdxl_base_v0.9",
      "length": 12
    },
    {
      "name": "V2 Dreamink",
      "file": "v2_dreamink_ti_f16.ckpt",
      "keyword": "v2_dreamink",
      "version": "v2",
      "length": 4
    },
    {
      "name": "Vintage Helper",
      "file": "vintagehelper_ti_f16.ckpt",
      "keyword": "vintagehelper",
      "version": "v2",
      "length": 8
    }
  ],
  "upscalers": []
}